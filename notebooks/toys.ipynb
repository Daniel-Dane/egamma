{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training mutually independent classifiers\n",
    "---\n",
    "This notebook show how to train mutually (linearly) independent classifiers using MSE loss on the linear correlation between classifier outputs. A simple toy dataset is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation\n",
    "---\n",
    "Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Basic import(s)\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import Image\n",
    "\n",
    "# Set Keras backend\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "# Keras import(s)\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.topology import Layer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# TensorFlow import(s)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Project import(s)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define fixed-seed random state, for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data arrays for input features and classification targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-659781ebdec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# -- Unit diagonal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcorr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# -- Ensure SPD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "# Classes\n",
    "num_classes  = 2\n",
    "\n",
    "# Features\n",
    "num_features = 6\n",
    "num_features_per_class = num_features // num_classes\n",
    "\n",
    "# Samples\n",
    "num_samples_per_class = 5000\n",
    "num_samples = num_samples_per_class * num_classes\n",
    "\n",
    "# Distributions widths\n",
    "widths = np.abs(1. + rng.randn(num_features) * 0.5)\n",
    "\n",
    "# Correlation matrix\n",
    "# -- Base matrix\n",
    "spread = 0.75\n",
    "corr   = rng.rand(num_features, num_features) * spread + (1. - spread)\n",
    "\n",
    "# -- Symmetrise\n",
    "corr += corr.T\n",
    "corr /= 2.\n",
    "\n",
    "# -- Unit diagonal\n",
    "I = np.eye(*corr.shape).astype(bool)\n",
    "corr[I] = 1\n",
    "\n",
    "# -- Ensure SPD\n",
    "good = False\n",
    "while not good:\n",
    "    try:\n",
    "        L = np.linalg.cholesky(corr)\n",
    "        good = True\n",
    "    except:\n",
    "        corr[I] += 0.001\n",
    "        pass\n",
    "    pass\n",
    "corr /= corr[0,0]\n",
    "\n",
    "# -- Cholesky decomposition\n",
    "L = np.linalg.cholesky(corr)\n",
    "Z = rng.randn(num_samples, num_features)  # Standard normals\n",
    "X = np.inner(Z, L)                        # Non-standard normals\n",
    "\n",
    "# Get classes\n",
    "sig = X[:num_samples_per_class, :]\n",
    "bkg = X[num_samples_per_class:, :]\n",
    "\n",
    "# Scale up\n",
    "sig *= widths\n",
    "bkg *= widths\n",
    "sig += widths * rng.randn(num_features) * 1.0\n",
    "\n",
    "# Create arrays (ordered)\n",
    "X  = np.vstack((sig, bkg))\n",
    "X1 = np.vstack((sig[:,:num_features_per_class], bkg[:,:num_features_per_class]))\n",
    "X2 = np.vstack((sig[:,num_features_per_class:], bkg[:,num_features_per_class:]))\n",
    "y = np.concatenate((np.ones((sig.shape[0],)), np.zeros((bkg.shape[0],))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num_features, num_features, figsize=(16,16))\n",
    "for i in range(num_features):\n",
    "    for j in range(num_features):\n",
    "        if j < i: \n",
    "            ax[i][j].axis('off')\n",
    "            continue\n",
    "        if i == j:\n",
    "            ax[i][j].hist(sig[:,i], bins=100,   alpha=0.5, color='red')\n",
    "            ax[i][j].hist(bkg[:,i], bins=100,   alpha=0.5, color='blue')\n",
    "            ax[i][j].set_xlabel('Feature {}'.format(i))\n",
    "        else:\n",
    "            ax[i][j].scatter(sig[:,i], sig[:,j], alpha=0.01, color='red')\n",
    "            ax[i][j].scatter(bkg[:,i], bkg[:,j], alpha=0.01, color='blue')\n",
    "        pass\n",
    "    pass\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle, split datasets into training- and test arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "idx = np.arange(y.size)\n",
    "rng.shuffle(idx)\n",
    "\n",
    "X  = X [idx,:]\n",
    "X1 = X1[idx,:]\n",
    "X2 = X2[idx,:]\n",
    "y  = y [idx]\n",
    "\n",
    "# Split into training and test\n",
    "num_train = int(0.8 * y.size)\n",
    "\n",
    "X1_train = X1[:num_train,:]\n",
    "X2_train = X2[:num_train,:]\n",
    "y_train  = y [:num_train]\n",
    "\n",
    "X1_test = X1[num_train:,:]\n",
    "X2_test = X2[num_train:,:]\n",
    "y_test  = y [num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot covariance matix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_ = np.corrcoef(bkg.T)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "plt.imshow(corr_, vmin=-1, vmax=1, cmap='RdBu')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Features')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standalone classifiers\n",
    "---\n",
    "Create, compile, and train neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "#arch_clf = [{\"units\": 16, \"activation\": \"relu\"}] * 3\n",
    "\n",
    "# Create networks\n",
    "clf1 = classifier_model(num_features_per_class)  #, arch_clf, scope='clf1')\n",
    "clf2 = classifier_model(num_features_per_class)  #, arch_clf, scope='clf2')\n",
    "\n",
    "# Compile\n",
    "clf1.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "clf2.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train\n",
    "ret1 = clf1.fit(X1_train, y_train, shuffle=True, epochs=30, validation_split=0.2, batch_size=128, verbose=0)\n",
    "ret2 = clf2.fit(X2_train, y_train, shuffle=True, epochs=30, validation_split=0.2, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot classifier losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "colors=['red', 'blue']\n",
    "linestyles=['-','--',':']\n",
    "for idx, ret in enumerate([ret1, ret2]):\n",
    "    for jdx, (name, loss) in enumerate(ret.history.iteritems()):\n",
    "        plt.plot(loss, color=colors[idx], linestyle=linestyles[jdx], label='{} (clf{})'.format(name, idx + 1))\n",
    "        pass\n",
    "    pass\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classifier loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot correlations between classifier predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classifier preductions\n",
    "pred1_test = clf1.predict(X1_test)\n",
    "pred2_test = clf2.predict(X2_test)\n",
    "\n",
    "# Compute correlation and ROC AUC\n",
    "rho = np.corrcoef(np.hstack((pred1_test, pred2_test)).T)[0,1]\n",
    "auc1 = roc_auc_score(y_test, pred1_test)\n",
    "auc2 = roc_auc_score(y_test, pred2_test)\n",
    "\n",
    "# Plot correlation\n",
    "msk = (y_test == 1)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.suptitle('Non-adversarial:\\n' + r'$\\rho = {:.3f}$ | AUC(1) = {:.3f} | AUC(2) = {:.3f}'.format(rho, auc1, auc2))\n",
    "plt.scatter(pred1_test[ msk], pred2_test[ msk], alpha=0.2, color='red',  label='Signal')\n",
    "plt.scatter(pred1_test[~msk], pred2_test[~msk], alpha=0.2, color='blue', label='Background')\n",
    "plt.xlabel(r'$\\tilde{y}_{1}$')\n",
    "plt.ylabel(r'$\\tilde{y}_{2}$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot classifier distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = (y_test == 1)\n",
    "bins = np.linspace(0, 1, 50 + 1, endpoint=True)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "# Classifier 1\n",
    "ax[0].set_title('AUC = {:.3f}'.format(auc1))\n",
    "ax[0].hist(pred1_test[ msk], bins=bins, alpha=0.5, color='red',  label='Signal')\n",
    "ax[0].hist(pred1_test[~msk], bins=bins, alpha=0.5, color='blue', label='Background')\n",
    "ax[0].set_xlabel(r'$\\tilde{y}_{1}$')\n",
    "\n",
    "# Classifier 2\n",
    "ax[1].set_title('AUC = {:.3f}'.format(auc2))\n",
    "ax[1].hist(pred2_test[ msk], bins=bins, alpha=0.5, color='red',  label='Signal')\n",
    "ax[1].hist(pred2_test[~msk], bins=bins, alpha=0.5, color='blue', label='Background')\n",
    "ax[1].set_xlabel(r'$\\tilde{y}_{2}$')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorrelated classifiers\n",
    "___\n",
    "\n",
    "Define custom decorrelation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_coefficient (x, y):\n",
    "    \"\"\"\n",
    "    Compute the linear correlation coefficient for input arrays `x` and `y` \n",
    "    using Keras backend methods.\n",
    "    \"\"\"\n",
    "    mx = K.mean(x)\n",
    "    my = K.mean(y)\n",
    "    xm, ym = x-mx, y-my\n",
    "    r_num = K.sum(tf.multiply(xm,ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / r_den\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "    return r\n",
    "\n",
    "class DecorrelationLayer (Layer):\n",
    "    \"\"\"\n",
    "    Custom Keras layer, outputting the linear correlation coefficient for the \n",
    "    outputs from the previous layers.\n",
    "    \"\"\"\n",
    "    def __init__ (self, **kwargs):\n",
    "        super(DecorrelationLayer, self).__init__(**kwargs)\n",
    "        pass\n",
    "\n",
    "    def build (self, input_shape):\n",
    "        return\n",
    "\n",
    "    def call (self, x, mask=None):\n",
    "        assert isinstance(x, list)\n",
    "        assert len(x) == 2\n",
    "        return correlation_coefficient(*x)\n",
    "\n",
    "    def compute_output_shape (self, input_shape):\n",
    "        return input_shape[:1]  # (None,)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "class LossRatioLayer (Layer):\n",
    "    \"\"\"\n",
    "    Custom Keras layer, outputting the ratio of losses of the outputs from the \n",
    "    previous layers.\n",
    "    \"\"\"\n",
    "    def __init__ (self, loss, **kwargs):\n",
    "        super(LossRatioLayer, self).__init__(**kwargs)\n",
    "        assert isinstance(loss, list)\n",
    "        assert len(loss) == 2\n",
    "        self._loss = loss\n",
    "        pass\n",
    "\n",
    "    def build (self, input_shape):\n",
    "        return\n",
    "\n",
    "    def call (self, x, mask=None):\n",
    "        assert isinstance(x, list)\n",
    "        assert len(x) == 4\n",
    "        # x = [pred_0, pred_1, targetr_0, target_1]\n",
    "        return K.mean(self._loss[0](K.flatten(x[0]), K.flatten(x[2])) / self._loss[1](K.flatten(x[1]), K.flatten(x[3])))\n",
    "\n",
    "    def compute_output_shape (self, input_shape):\n",
    "        return input_shape[:1]  # (None,)\n",
    "\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom `Decorrelator` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decorrelator (object):\n",
    "\n",
    "    def __init__ (self, clf1, clf2, lambda_reg=100., beta_reg=10.):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "    \n",
    "        # Check(s)\n",
    "        # ...\n",
    "        \n",
    "        self._clf1 = clf1\n",
    "        self._clf2 = clf2\n",
    "        \n",
    "        self._lambda = lambda_reg\n",
    "        self._beta   = beta_reg\n",
    "\n",
    "        self._targets = None\n",
    "        self._loss    = None\n",
    "        self._model   = None\n",
    "        return\n",
    "    \n",
    "    def _build (self):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "        \n",
    "        # Reconstruct classifier\n",
    "        input_clf1 = Input(shape=self._clf1.layers[0].input_shape[1:])\n",
    "        input_clf2 = Input(shape=self._clf2.layers[0].input_shape[1:])\n",
    "        \n",
    "        output_clf1 = self._clf1(input_clf1)\n",
    "        output_clf2 = self._clf2(input_clf2)\n",
    "        \n",
    "        # Target inputs, for balancing\n",
    "        target_clf1 = Input(shape=self._clf1.layers[-1].output_shape[1:])\n",
    "        target_clf2 = Input(shape=self._clf2.layers[-1].output_shape[1:])\n",
    "        \n",
    "        # Add decorrelation layer\n",
    "        corr = DecorrelationLayer()([output_clf1, output_clf2])\n",
    "        \n",
    "        # Add balance layer\n",
    "        balance = LossRatioLayer(loss=self._loss)([output_clf1, output_clf2, target_clf1, target_clf2])\n",
    "\n",
    "        # Build model\n",
    "        self._model = Model(inputs =[input_clf1,  input_clf2, target_clf1, target_clf2],\n",
    "                            outputs=[output_clf1, output_clf2, corr, balance],\n",
    "                            name='decorrelator')\n",
    "        return\n",
    "\n",
    "    \n",
    "    def compile (self, loss, **kwargs):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check(s)\n",
    "        if not isinstance(loss, list):\n",
    "            loss = list(loss)\n",
    "            pass\n",
    "        self._loss = [keras.losses.get(l) for l in loss]\n",
    "\n",
    "        # Internal build method\n",
    "        self._build()\n",
    "\n",
    "        # Compile underlying model\n",
    "        self._model.compile(loss=self._loss + ['MSE', 'MSE'], loss_weights=[1., 1., self._lambda, self._beta], **kwargs)\n",
    "        return\n",
    "\n",
    "    \n",
    "    def fit (self, inputs, targets, **kwargs):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check(s)\n",
    "        if not isinstance(targets, list):\n",
    "            targets = list(targets)\n",
    "            pass\n",
    "        self._targets = targets\n",
    "        self._inputs  = inputs\n",
    "\n",
    "        # Compute target loss ratio\n",
    "        # @TODO: Use loss functions!\n",
    "        print \"Evaluating classifiers before fitting.\"\n",
    "        loss_num = self._clf1.evaluate(self._inputs[0], self._targets[0])\n",
    "        loss_den = self._clf2.evaluate(self._inputs[1], self._targets[1])\n",
    "        loss_ratio = np.ones((self._targets[0].shape[0],)) * loss_num / loss_den\n",
    "        print \"Target loss ratio: {} / {} = {}\".format(loss_num, loss_den, loss_ratio[0])\n",
    "        \n",
    "        # Actual fit method\n",
    "        zeros = np.zeros((self._targets[0].shape[0],))\n",
    "        ret = self._model.fit(self._inputs + self._targets, self._targets + [zeros, loss_ratio], **kwargs)\n",
    "        \n",
    "        # Log balancing result\n",
    "        loss_num = self._clf1.evaluate(self._inputs[0], self._targets[0])\n",
    "        loss_den = self._clf2.evaluate(self._inputs[1], self._targets[1])\n",
    "        loss_ratio = loss_num / loss_den\n",
    "        print \"Final loss ratio:  {} / {} = {}\".format(loss_num, loss_den, loss_ratio)\n",
    "        return ret\n",
    "        \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `Decorrelator` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decorr = Decorrelator(clf1, clf2, lambda_reg=1.0E+02, beta_reg=1.0E+02)\n",
    "\n",
    "# Define optimiser.\n",
    "adam = Adam(lr=1.0E-05)\n",
    "\n",
    "# Compile\n",
    "decorr.compile(loss=['binary_crossentropy', 'binary_crossentropy'], optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir('figures/')\n",
    "plot_model(clf1, to_file='figures/classifier.png', show_shapes=True)\n",
    "plot_model(decorr._model, to_file='figures/decorrelator.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/classifier.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Decorrelator` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/decorrelator.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimiser, compile and train `Decorrelator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "ret = decorr.fit([X1_train, X2_train], [y_train, y_train], shuffle=True, epochs=30 * 10, validation_split=0.2, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot `Decorrelator` training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for idx, (name, loss) in enumerate(ret.history.iteritems()):\n",
    "    color='red' if 'clf' in name else ('blue' if 'adv' in name else 'black')\n",
    "    linestyle='--' if 'val' in name else '-'\n",
    "    plt.plot(loss, color=color, linestyle=linestyle, label=name)\n",
    "    pass\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Frenemies loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot correlations between classifier predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classifier preditions\n",
    "pred1_test = clf1.predict(X1_test)\n",
    "pred2_test = clf2.predict(X2_test)\n",
    "\n",
    "# Compute correlation and ROC AUC\n",
    "rho = np.corrcoef(np.hstack((pred1_test, pred2_test)).T)[0,1]\n",
    "auc1 = roc_auc_score(y_test, pred1_test)\n",
    "auc2 = roc_auc_score(y_test, pred2_test)\n",
    "\n",
    "# Plot correlation\n",
    "msk = (y_test == 1)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.suptitle('Adversarial:\\n' + r'$\\rho = {:.3f}$ | AUC(1) = {:.3f} | AUC(2) = {:.3f}'.format(rho, auc1, auc2))\n",
    "plt.scatter(pred1_test[ msk], pred2_test[ msk], alpha=0.2, color='red',  label='Signal')\n",
    "plt.scatter(pred1_test[~msk], pred2_test[~msk], alpha=0.2, color='blue', label='Background')\n",
    "plt.xlabel(r'$\\tilde{y}_{1}$')\n",
    "plt.ylabel(r'$\\tilde{y}_{2}$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot classifier distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = (y_test == 1)\n",
    "bins = np.linspace(0, 1, 50 + 1, endpoint=True)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "# Classifier 1\n",
    "ax[0].set_title('AUC = {:.3f}'.format(auc1))\n",
    "ax[0].hist(pred1_test[ msk], bins=bins, alpha=0.5, color='red',  label='Signal')\n",
    "ax[0].hist(pred1_test[~msk], bins=bins, alpha=0.5, color='blue', label='Background')\n",
    "ax[0].set_xlabel(r'$\\tilde{y}_{1}$')\n",
    "\n",
    "# Classifier 2\n",
    "ax[1].set_title('AUC = {:.3f}'.format(auc2))\n",
    "ax[1].hist(pred2_test[ msk], bins=bins, alpha=0.5, color='red',  label='Signal')\n",
    "ax[1].hist(pred2_test[~msk], bins=bins, alpha=0.5, color='blue', label='Background')\n",
    "ax[1].set_xlabel(r'$\\tilde{y}_{2}$')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
